# Titanic-Dataset-Survival-Prediction-

Welcome to this Titanic project. This is my first kernel at Kaggle. In this notebook, I'm going to predict wether a passenger of the famous boat will survive or not. Firstly, I will display some feature analyses then ill focus on the feature engineering. Last part concerns modeling and predicting the survival on the Titanic using an voting procedure. If you find a way to improve it I encourage you to fork this notebook and contribute by adding a better solution.

I have explained the Exploratory Data Analysis and the Feature Engineering that was carried out to best understand the data and also to better train the Neural Network.

I started modeling the data with logistic regression to see how it performs and then gradually moved upwards from there and tried different algorithms KNN, SVM, Decsion trees, Random forest and xGBoost. I submitted th results of the Random forest and also an ensemble techique where I combined te results from all the models. The best score I got was 0.75 which is not good so I tried an ANN afer that.

*Best results : 79.186% accuracy (Neural Network) *
